{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/topcover.jpg\" width=\"1000\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In earlier notebooks, it is seen that classification between Stroma and Tumour images has potential to improve diagnosis and shed light on the severity of the disease based on the Tumour: Stroma ratio. After diagnosis, treatments for cancer can be made more personalised if more information is known about the type of mutations driving colorectal cancer in the patient. Therefore, clinical text data on colorectal cancer can help to identify the possible mutation type. If treatments are available for that particular mutation, that treatment can be administered. Otherwise, research can be carried out to find novel treatments for various mutation types related to colorectal cancer. \n",
    "\n",
    "##### In addition, a correlation could also be associated between the tumour:stroma ratio, or morphology/texture of the cell with the type of mutation for research purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports relevant modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# Import CountVectorizer from feature_extraction.text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_colorectal = pd.read_csv('../data/train_colorectal.csv')\n",
    "train_nlp = pd.read_csv('../data/train_colorectal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>sequencing studies have identified many recurr...</td>\n",
       "      <td>TERT</td>\n",
       "      <td>C228T</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>sequencing studies have identified many recurr...</td>\n",
       "      <td>TERT</td>\n",
       "      <td>Promoter Mutations</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>the current world health organization classifi...</td>\n",
       "      <td>TERT</td>\n",
       "      <td>Amplification</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>sequencing studies have identified many recurr...</td>\n",
       "      <td>TERT</td>\n",
       "      <td>C250T</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>abstract  dicer plays a critical role in micr...</td>\n",
       "      <td>DICER1</td>\n",
       "      <td>G1809R</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>3256</td>\n",
       "      <td>neuroblastoma the most common paediatric solid...</td>\n",
       "      <td>CASP8</td>\n",
       "      <td>Promoter Hypermethylation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>3262</td>\n",
       "      <td>ret is a singlepass transmembrane receptor tyr...</td>\n",
       "      <td>RET</td>\n",
       "      <td>S891A</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>3269</td>\n",
       "      <td>oncogenic fusion of the ret rearranged during ...</td>\n",
       "      <td>RET</td>\n",
       "      <td>Fusions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>3278</td>\n",
       "      <td>ret is a singlepass transmembrane receptor tyr...</td>\n",
       "      <td>RET</td>\n",
       "      <td>A883F</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>3310</td>\n",
       "      <td>runx proteins belong to a family of metazoan t...</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>Amplification</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Text    Gene  \\\n",
       "0      28  sequencing studies have identified many recurr...    TERT   \n",
       "1      31  sequencing studies have identified many recurr...    TERT   \n",
       "2      33  the current world health organization classifi...    TERT   \n",
       "3      34  sequencing studies have identified many recurr...    TERT   \n",
       "4      35   abstract  dicer plays a critical role in micr...  DICER1   \n",
       "..    ...                                                ...     ...   \n",
       "916  3256  neuroblastoma the most common paediatric solid...   CASP8   \n",
       "917  3262  ret is a singlepass transmembrane receptor tyr...     RET   \n",
       "918  3269  oncogenic fusion of the ret rearranged during ...     RET   \n",
       "919  3278  ret is a singlepass transmembrane receptor tyr...     RET   \n",
       "920  3310  runx proteins belong to a family of metazoan t...   RUNX1   \n",
       "\n",
       "                     Variation  Class  \n",
       "0                        C228T      7  \n",
       "1           Promoter Mutations      7  \n",
       "2                Amplification      2  \n",
       "3                        C250T      7  \n",
       "4                       G1809R      4  \n",
       "..                         ...    ...  \n",
       "916  Promoter Hypermethylation      4  \n",
       "917                      S891A      7  \n",
       "918                    Fusions      2  \n",
       "919                      A883F      7  \n",
       "920              Amplification      7  \n",
       "\n",
       "[921 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data for modelling\n",
    "\n",
    "X = train_nlp['Text']\n",
    "y = train_nlp['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    0.378936\n",
       "1    0.187839\n",
       "4    0.156352\n",
       "2    0.143322\n",
       "5    0.049946\n",
       "6    0.048860\n",
       "3    0.019544\n",
       "9    0.008686\n",
       "8    0.006515\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution since this is a classification problem\n",
    "\n",
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into the training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our CountVectorizer with default parameter and exclude stop words\n",
    "\n",
    "cvec = CountVectorizer(analyzer='word', tokenizer=LemmaTokenizer(), ngram_range=(1, 1))\n",
    "# max_features=1000    addddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tresha\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x0000008A075DD550>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the vectorizer on our corpus.\n",
    "cvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the corpus.\n",
    "X_train = cvec.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<736x82232 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1387628 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736, 82232)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe x shape\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+a',\n",
       " '+ap',\n",
       " '+association',\n",
       " '+at',\n",
       " '+bach',\n",
       " '+bp',\n",
       " '+chx',\n",
       " '+d',\n",
       " '+dd',\n",
       " '+delptpqp',\n",
       " '+distal',\n",
       " '+dmso',\n",
       " '+dox',\n",
       " '+edel',\n",
       " '+egf']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cvec.get_feature_names()[10:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test\n",
    "X_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 82232)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose multinomial naiive bayes\n",
    "\n",
    "# instantiate our model\n",
    "\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our model\n",
    "\n",
    "model = nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate our predictions\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7771739130434783"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score of our model on the training set.\n",
    "\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5945945945945946"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score of our model on the testing set.\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 5, 4, 4, 4, 2, 4, 1, 6, 1, 7, 6, 7, 1, 7, 2, 7, 7, 7, 1, 7,\n",
       "       7, 7, 7, 7, 2, 7, 4, 7, 4, 5, 7, 4, 7, 4, 5, 7, 7, 4, 7, 1, 7, 2,\n",
       "       7, 1, 4, 7, 9, 7, 4, 2, 1, 4, 5, 7, 7, 1, 7, 5, 7, 4, 2, 1, 5, 7,\n",
       "       2, 2, 7, 7, 2, 2, 7, 7, 7, 7, 4, 1, 7, 7, 1, 7, 9, 7, 7, 1, 7, 1,\n",
       "       7, 4, 7, 4, 3, 1, 2, 4, 1, 7, 7, 7, 5, 1, 7, 7, 7, 1, 2, 7, 7, 7,\n",
       "       7, 7, 7, 4, 4, 1, 7, 7, 7, 2, 1, 2, 1, 1, 1, 2, 2, 1, 7, 2, 1, 1,\n",
       "       6, 5, 3, 7, 7, 7, 1, 7, 6, 7, 7, 7, 4, 1, 7, 4, 1, 2, 1, 7, 4, 1,\n",
       "       1, 7, 7, 5, 7, 7, 1, 1, 7, 1, 2, 2, 4, 7, 7, 1, 3, 7, 1, 2, 7, 1,\n",
       "       7, 1, 7, 7, 1, 3, 7, 7, 2], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5795299621757659"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score1 = f1_score(y_test, predictions, average='weighted')\n",
    "f1_score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN using GridSearch to find optimum KNN value\n",
    "\n",
    "knn = KNeighborsClassifier() \n",
    "opt_knn = GridSearchCV(knn, param_grid, cv=5)\n",
    "opt_knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 6, 'weights': 'distance'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check knn best parameter\n",
    "\n",
    "opt_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "predictions1 = opt_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279891304347826"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5243243243243243"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_knn.score(X_test, y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5080688207003996"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score2 = f1_score(y_test, predictions1,average='weighted')\n",
    "f1_score2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate support vector machine.\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV(estimator=SVC(),\n",
    "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf', 'poly'), 'degree':[2]})\n",
    "gs1.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = gs1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7635869565217391"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6162162162162163"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5712320911561898"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score3 = f1_score(y_test, predictions2,average='weighted')\n",
    "f1_score3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tresha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mean score: 0.6047\n"
     ]
    }
   ],
   "source": [
    "pre_score = cross_val_score(estimator = rf,\n",
    "                            X = X_train, \n",
    "                            y = y_train,\n",
    "                            scoring = 'accuracy',\n",
    "                            cv = 10,\n",
    "                            verbose = 0)\n",
    "\n",
    "print('Random Forest mean score: %5.4f' %np.mean(pre_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6073175216032359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 150}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearch for random forests\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(rf, param_grid=rf_params, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9293478260869565"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests using GridSearchCV\n",
    "\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5837837837837838"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests using GridSearchCV\n",
    "\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5549556680055967"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score4 = f1_score(y_test, predictions3,average='weighted')\n",
    "f1_score4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear', \n",
    "                        max_iter = 1000,\n",
    "                        random_state = 42)\n",
    "\n",
    "gs_results = GridSearchCV(estimator = lr,                                    # Specify the model we want to GridSearch.\n",
    "                          param_grid = parameters,                           # Specify the grid of parameters we want to search.\n",
    "                          scoring = 'accuracy',                                # Specify recall as the metric to optimize \n",
    "                          cv = 5).fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5842158485015628"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(\n",
    " C= 0.01,\n",
    " class_weight= None,\n",
    " dual= False,\n",
    " fit_intercept= True,\n",
    " intercept_scaling= 1,\n",
    " l1_ratio= None,\n",
    " max_iter= 1000,\n",
    " multi_class= 'auto',\n",
    " n_jobs= None,\n",
    " penalty= 'l1',\n",
    " random_state= 42,\n",
    " solver= 'liblinear',\n",
    " tol= 0.0001,\n",
    " verbose= 0,\n",
    " warm_start= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=1000, penalty='l1', random_state=42,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logit.fit(X = X_train,\n",
    "          y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7581521739130435"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5405405405405406"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4 = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5153100562347647"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score5 = f1_score(y_test, predictions4,average='weighted')\n",
    "f1_score5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary table for Classification of Clinical Text data into 9 classes of mutation types:**\n",
    "\n",
    "| Model| Test Accuracy|F1 score|Baseline score for largest class|\n",
    "|:---------:|:---:|:--------:|:--------:|\n",
    "|  Naiive Bayes |    0.594 | 0.580   |  0.379  |\n",
    "|KNN|  0.524| 0.508   |0.379 |\n",
    "|SVC| 0.616|  0.571 | 0.379 |\n",
    "|Random Forests|0.584| 0.555   |0.379 |\n",
    "|Logistic Regression|0.541| 0.515    |0.379 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM has the best score of 0.616. The generally low score could be attributed to the unbalanced classes and less amount of data. However, if more data is added and model improved, it could prove to be useful to classify text data into mutation types. This can help to filter out patients that could receive treatments that already exists for a particular mutation type. Otherwise, research is carried out to find novel therapies for other mutation types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Both models at their optimum can be used to train new pathologists and aid them in making better diagnosis as it takes 10 years of training to have an eye for detail and decipher between tissue types and cancers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R.E.A.D\n",
    "\n",
    "##### All in all, both models can be used for Research, Education and Diagnostics purposes if improved and optimised. A website is created using FLASK for this multipurpose classification. A forum page is also added to discuss research articles and journals related to colorectal cancer diagnosis and treatments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/topcover.jpg\" width=\"1000\" height=\"50\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
