{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/topcover.jpg\" width=\"1000\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:teal\"> Image Classification : Stroma vs Tumour </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook classifies images of two tissue types namely, stroma and tumour for better results and accuracy as compared to classifying into 8 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data generator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, # rotation\n",
    "        width_shift_range=0.2, # horizontal shift\n",
    "        height_shift_range=0.2, # vertical shift\n",
    "        zoom_range=0.2, # zoom\n",
    "        horizontal_flip=True, # horizontal flip\n",
    "        brightness_range=[0.2,1.2]) # brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 834 images belonging to 2 classes.\n",
      "Found 425 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('../data/val1/', class_mode='binary', batch_size=5)\n",
    "# load and iterate validation dataset\n",
    "val_it = datagen.flow_from_directory('../data/train/', class_mode='binary', batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape=(5, 256, 256, 3), min=0.000, max=255.000\n"
     ]
    }
   ],
   "source": [
    "# batch shape\n",
    "\n",
    "batchX, batchy = train_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run Convulation Neural Network Model using images as data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "16/16 [==============================] - 39s 2s/step - loss: 37.7115 - accuracy: 0.5193 - val_loss: 1.6925 - val_accuracy: 0.5120\n",
      "Epoch 2/12\n",
      "16/16 [==============================] - 38s 2s/step - loss: 1.6197 - accuracy: 0.4886 - val_loss: 0.6486 - val_accuracy: 0.6400\n",
      "Epoch 3/12\n",
      "16/16 [==============================] - 39s 3s/step - loss: 0.4632 - accuracy: 0.8232 - val_loss: 0.4294 - val_accuracy: 0.8080\n",
      "Epoch 4/12\n",
      "16/16 [==============================] - 40s 3s/step - loss: 0.3808 - accuracy: 0.8803 - val_loss: 0.3039 - val_accuracy: 0.8880\n",
      "Epoch 5/12\n",
      "16/16 [==============================] - 40s 3s/step - loss: 1.2387 - accuracy: 0.5239 - val_loss: 0.5296 - val_accuracy: 0.5680\n",
      "Epoch 6/12\n",
      "16/16 [==============================] - 40s 3s/step - loss: 0.5749 - accuracy: 0.5523 - val_loss: 0.4570 - val_accuracy: 0.6800\n",
      "Epoch 7/12\n",
      "16/16 [==============================] - 45s 3s/step - loss: 0.6190 - accuracy: 0.6417 - val_loss: 0.6931 - val_accuracy: 0.4960\n",
      "Epoch 8/12\n",
      "16/16 [==============================] - 45s 3s/step - loss: 0.6928 - accuracy: 0.5090 - val_loss: 0.6934 - val_accuracy: 0.4960\n",
      "Epoch 9/12\n",
      "16/16 [==============================] - 38s 2s/step - loss: 0.6885 - accuracy: 0.5496 - val_loss: 0.6919 - val_accuracy: 0.4960\n",
      "Epoch 10/12\n",
      "16/16 [==============================] - 40s 3s/step - loss: 0.6793 - accuracy: 0.6459 - val_loss: 0.6985 - val_accuracy: 0.4160\n",
      "Epoch 11/12\n",
      "16/16 [==============================] - 38s 2s/step - loss: 0.6955 - accuracy: 0.4468 - val_loss: 0.6881 - val_accuracy: 0.4960\n",
      "Epoch 12/12\n",
      "16/16 [==============================] - 38s 2s/step - loss: 0.6865 - accuracy: 0.6057 - val_loss: 0.6682 - val_accuracy: 0.7120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x163e7a19d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128,             # number of filters\n",
    "                       kernel_size=(5,5),      # height/width of filter\n",
    "                       activation='relu',\n",
    "                       padding = 'same',# activation function \n",
    "                       input_shape=(256, 256, 3))) # shape of input (image)\n",
    "\n",
    "# Add a pooling layer.\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "# Add another convolutional layer.\n",
    "model.add(Conv2D(64,\n",
    "                       kernel_size=(3,3),\n",
    "                       activation='relu'))\n",
    "\n",
    "# Add another pooling layer.\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# Add another convolutional layer.\n",
    "model.add(Conv2D(64,\n",
    "                       kernel_size=(3,3),\n",
    "                       activation='relu'))\n",
    "\n",
    "# Add another pooling layer.\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit model\n",
    "model.fit(train_it,epochs = 12, steps_per_epoch=16, validation_data=val_it, validation_steps=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN validation accuracy results are 0.7120. This model performs poorer than pixel data to classify histopathological images based on stroma vs tumour. This notion is supported by this [*source*](https://www.hindawi.com/journals/ijbi/2012/792079/)  which mentions that pixel-based machine learning could potentially avoid errors caused by inaccurate feature calculation and segmentation which often occur for complex objects. In addition, pixel data could take up less memory for storage and classification.\n",
    "\n",
    " \n",
    "\n",
    "### In reality, the tissues obtained will be a mixture of stroma and tomour tissues!Therefore, the image uploaded will be annotated by the pathologist as the area on interest. The platform should convert that area of interest into pixel data for classification since pixel data performs better and takes up less storage space.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
