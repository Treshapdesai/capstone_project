{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/topcover.jpg\" width=\"1000\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In earlier notebooks, it is seen that classification between Stroma and Tumour images has potential to improve diagnosis and shed light on the severity of the disease based on the stroma-rich or stroma-poor groups. After diagnosis, treatments for cancer can be made more personalised if more information is known about the type of mutations driving colorectal cancer in the patient. Therefore, clinical text data on colorectal cancer can help to identify the possible mutation type. If treatments are available for that particular mutation, that treatment can be administered. Otherwise, research can be carried out to find novel treatments for various mutation types related to colorectal cancer. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports relevant modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# Import CountVectorizer from feature_extraction.text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\tresha\\anaconda3\\lib\\site-packages (0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\tresha\\anaconda3\\lib\\site-packages (from imblearn) (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\tresha\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\tresha\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\tresha\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.3)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\tresha\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tresha\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: delayed in c:\\users\\tresha\\anaconda3\\lib\\site-packages (0.11.0b1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: redis in c:\\users\\tresha\\anaconda3\\lib\\site-packages (from delayed) (3.5.3)\n",
      "Requirement already satisfied: hiredis in c:\\users\\tresha\\anaconda3\\lib\\site-packages (from delayed) (2.0.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_colorectal = pd.read_csv('../data/train_colorectal.csv')\n",
    "train_nlp = pd.read_csv('../data/traincolorectal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>sequencing studies have identified many recurr...</td>\n",
       "      <td>TERT</td>\n",
       "      <td>C228T</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>sequencing studies have identified many recurr...</td>\n",
       "      <td>TERT</td>\n",
       "      <td>Promoter Mutations</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>the current world health organization classifi...</td>\n",
       "      <td>TERT</td>\n",
       "      <td>Amplification</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>sequencing studies have identified many recurr...</td>\n",
       "      <td>TERT</td>\n",
       "      <td>C250T</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>abstract  dicer plays a critical role in micr...</td>\n",
       "      <td>DICER1</td>\n",
       "      <td>G1809R</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>3256</td>\n",
       "      <td>neuroblastoma the most common paediatric solid...</td>\n",
       "      <td>CASP8</td>\n",
       "      <td>Promoter Hypermethylation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>3262</td>\n",
       "      <td>ret is a singlepass transmembrane receptor tyr...</td>\n",
       "      <td>RET</td>\n",
       "      <td>S891A</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>3269</td>\n",
       "      <td>oncogenic fusion of the ret rearranged during ...</td>\n",
       "      <td>RET</td>\n",
       "      <td>Fusions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>3278</td>\n",
       "      <td>ret is a singlepass transmembrane receptor tyr...</td>\n",
       "      <td>RET</td>\n",
       "      <td>A883F</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>3310</td>\n",
       "      <td>runx proteins belong to a family of metazoan t...</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>Amplification</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Text    Gene  \\\n",
       "0      28  sequencing studies have identified many recurr...    TERT   \n",
       "1      31  sequencing studies have identified many recurr...    TERT   \n",
       "2      33  the current world health organization classifi...    TERT   \n",
       "3      34  sequencing studies have identified many recurr...    TERT   \n",
       "4      35   abstract  dicer plays a critical role in micr...  DICER1   \n",
       "..    ...                                                ...     ...   \n",
       "916  3256  neuroblastoma the most common paediatric solid...   CASP8   \n",
       "917  3262  ret is a singlepass transmembrane receptor tyr...     RET   \n",
       "918  3269  oncogenic fusion of the ret rearranged during ...     RET   \n",
       "919  3278  ret is a singlepass transmembrane receptor tyr...     RET   \n",
       "920  3310  runx proteins belong to a family of metazoan t...   RUNX1   \n",
       "\n",
       "                     Variation  Class  \n",
       "0                        C228T      7  \n",
       "1           Promoter Mutations      7  \n",
       "2                Amplification      2  \n",
       "3                        C250T      7  \n",
       "4                       G1809R      4  \n",
       "..                         ...    ...  \n",
       "916  Promoter Hypermethylation      4  \n",
       "917                      S891A      7  \n",
       "918                    Fusions      2  \n",
       "919                      A883F      7  \n",
       "920              Amplification      7  \n",
       "\n",
       "[921 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data for modelling\n",
    "\n",
    "X = train_nlp['Text']\n",
    "y = train_nlp['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    0.378936\n",
       "1    0.187839\n",
       "4    0.156352\n",
       "2    0.143322\n",
       "5    0.049946\n",
       "6    0.048860\n",
       "3    0.019544\n",
       "9    0.008686\n",
       "8    0.006515\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution since this is a classification problem\n",
    "\n",
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our CountVectorizer with default parameter and exclude stop words\n",
    "\n",
    "cvec = CountVectorizer(analyzer='word', tokenizer=LemmaTokenizer(), ngram_range=(1, 1))\n",
    "# max_features=1000    addddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cvec.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into the training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552, 91254)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe x shape\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+a',\n",
       " '+ap',\n",
       " '+association',\n",
       " '+at',\n",
       " '+bach',\n",
       " '+bp',\n",
       " '+byl',\n",
       " '+cetuximab',\n",
       " '+chemo',\n",
       " '+chx',\n",
       " '+cobimetinib',\n",
       " '+d',\n",
       " '+dd',\n",
       " '+delptpqp',\n",
       " '+distal']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cvec.get_feature_names()[10:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 91254)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tackle imbalanced classes\n",
    "\n",
    "X_resample, y_resampled = SMOTE(k_neighbors=2).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose multinomial naiive bayes\n",
    "\n",
    "# instantiate our model\n",
    "\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our model\n",
    "\n",
    "model = nb.fit(X_resample, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate our predictions\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8787878787878788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score of our model on the training set.\n",
    "\n",
    "model.score(X_resample, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5934959349593496"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score of our model on the testing set.\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7, 2, 7, 7, 7, 1, 6, 1, 5, 7, 7, 7, 6, 2, 7, 1, 1, 2, 6, 9,\n",
       "       7, 1, 2, 3, 3, 7, 5, 7, 7, 2, 1, 4, 3, 4, 1, 7, 2, 3, 7, 4, 7, 7,\n",
       "       2, 7, 1, 1, 7, 7, 7, 4, 7, 6, 5, 7, 7, 7, 7, 6, 7, 2, 2, 5, 5, 7,\n",
       "       7, 7, 2, 2, 7, 7, 4, 7, 5, 1, 7, 3, 1, 4, 7, 4, 5, 7, 7, 1, 1, 7,\n",
       "       7, 1, 2, 7, 7, 4, 1, 7, 2, 6, 3, 2, 7, 2, 7, 1, 7, 2, 2, 2, 7, 7,\n",
       "       5, 3, 1, 7, 4, 3, 1, 7, 7, 7, 2, 7, 1, 6, 4, 5, 1, 1, 7, 5, 7, 4,\n",
       "       7, 1, 6, 1, 7, 1, 4, 7, 2, 4, 4, 4, 1, 2, 7, 1, 2, 3, 2, 1, 7, 7,\n",
       "       1, 1, 7, 2, 1, 1, 5, 1, 1, 1, 2, 1, 7, 1, 7, 2, 7, 7, 1, 2, 2, 1,\n",
       "       2, 1, 4, 7, 4, 2, 1, 7, 5, 7, 7, 7, 5, 2, 7, 6, 7, 9, 7, 1, 1, 7,\n",
       "       2, 1, 1, 7, 7, 7, 7, 2, 1, 2, 7, 5, 7, 7, 7, 1, 2, 2, 1, 7, 5, 7,\n",
       "       1, 6, 2, 5, 1, 7, 7, 7, 2, 5, 7, 2, 1, 7, 7, 1, 1, 6, 7, 7, 1, 1,\n",
       "       7, 4, 1, 5, 7, 2, 4, 7, 1, 3, 1, 5, 1, 7, 7, 7, 1, 1, 3, 7, 3, 2,\n",
       "       1, 7, 2, 7, 7, 2, 7, 3, 1, 2, 4, 7, 1, 3, 3, 1, 4, 6, 7, 1, 5, 5,\n",
       "       4, 5, 3, 2, 7, 2, 1, 2, 7, 7, 9, 1, 7, 7, 4, 7, 1, 2, 7, 1, 2, 1,\n",
       "       7, 7, 4, 1, 1, 1, 7, 7, 2, 2, 7, 2, 2, 7, 7, 1, 4, 2, 5, 7, 1, 7,\n",
       "       7, 2, 1, 1, 7, 7, 7, 7, 2, 7, 1, 1, 7, 7, 7, 1, 7, 1, 7, 7, 4, 1,\n",
       "       1, 1, 7, 7, 7, 7, 7, 1, 7, 5, 5, 6, 7, 4, 7, 7, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5892954573084404"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score1 = f1_score(y_test, predictions, average='weighted')\n",
    "f1_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tresha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6170202102392158"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision1 = precision_score(y_test, predictions, average='weighted')\n",
    "precision1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN using GridSearch to find optimum KNN value\n",
    "\n",
    "knn = KNeighborsClassifier() \n",
    "opt_knn = GridSearchCV(knn, param_grid, cv=2)\n",
    "opt_knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 12, 'weights': 'distance'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check knn best parameter\n",
    "\n",
    "opt_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "predictions1 = opt_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9293478260869565"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5149051490514905"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_knn.score(X_test, y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49983779625370117"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score2 = f1_score(y_test, predictions1,average='weighted')\n",
    "f1_score2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tresha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5092730810032968"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision2 = precision_score(y_test, predictions1, average='weighted',zero_division='warn')\n",
    "precision2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate support vector machine.\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tresha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "gs1 = GridSearchCV(estimator=SVC(),\n",
    "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf', 'poly'), 'degree':[2]})\n",
    "gs1.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = gs1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7590579710144928"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6016260162601627"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629585219156645"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score3 = f1_score(y_test, predictions2,average='weighted')\n",
    "f1_score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tresha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5750412048871787"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision3 = precision_score(y_test, predictions2, average='weighted', zero_division='warn')\n",
    "precision3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mean score: 0.5453\n"
     ]
    }
   ],
   "source": [
    "pre_score = cross_val_score(estimator = rf,\n",
    "                            X = X_train, \n",
    "                            y = y_train,\n",
    "                            scoring = 'accuracy',\n",
    "                            cv = 2,\n",
    "                            verbose = 0)\n",
    "\n",
    "print('Random Forest mean score: %5.4f' %np.mean(pre_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5416666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 150}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearch for random forests\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(rf, param_grid=rf_params, cv=2)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9293478260869565"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests using GridSearchCV\n",
    "\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5799457994579946"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests using GridSearchCV\n",
    "\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.549451199881517"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score4 = f1_score(y_test, predictions3,average='weighted')\n",
    "f1_score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tresha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5658797770479412"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision4 = precision_score(y_test, predictions3, average='weighted', zero_division='warn')\n",
    "precision4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear', \n",
    "                        max_iter = 1000,\n",
    "                        random_state = 42)\n",
    "\n",
    "gs_results = GridSearchCV(estimator = lr,                                    # Specify the model we want to GridSearch.\n",
    "                          param_grid = parameters,                           # Specify the grid of parameters we want to search.\n",
    "                          scoring = 'accuracy',                                # Specify recall as the metric to optimize \n",
    "                          cv = 2).fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5670289855072463"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(\n",
    " C= 0.01,\n",
    " class_weight= None,\n",
    " dual= False,\n",
    " fit_intercept= True,\n",
    " intercept_scaling= 1,\n",
    " l1_ratio= None,\n",
    " max_iter= 1000,\n",
    " multi_class= 'auto',\n",
    " n_jobs= None,\n",
    " penalty= 'l1',\n",
    " random_state= 42,\n",
    " solver= 'liblinear',\n",
    " tol= 0.0001,\n",
    " verbose= 0,\n",
    " warm_start= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=1000, penalty='l1', random_state=42,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logit.fit(X = X_train,\n",
    "          y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518115942028986"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5718157181571816"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4 = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5508437337406842"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score5 = f1_score(y_test, predictions4,average='weighted')\n",
    "f1_score5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tresha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5437328867088181"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision5 = precision_score(y_test, predictions4, average='weighted', zero_division='warn')\n",
    "precision5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary table for Classification of Clinical Text data into 9 classes of mutation types:**\n",
    "\n",
    "| Model| Test Accuracy|Precision|Baseline score for largest class|\n",
    "|:---------:|:---:|:--------:|:--------:|\n",
    "|  Naiive Bayes |    0.600 | 0.620  |  0.379  |\n",
    "|KNN|  0.515| 0.510   |0.379 |\n",
    "|SVC| 0.602|  0.575 | 0.379 |\n",
    "|Random Forests|0.610| 0.555   |0.379 |\n",
    "|Logistic Regression|0.572| 0.544    |0.379 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naiive Bayes has the top best precision score of 0.620 respectively. The generally low score could be attributed to the imbalanced classes and less amount of data. The imbalanced classes have been tackled by using SMOT as an oversampler.  However, if more data is added and model improved, it can prove to be highly useful to classify text data into mutation types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification of various colorectal cancer tissues is made possible with machine learning. This helps to support pathologists' increasing workload by enhancing diagnostic capabilities. At the same time, provide an avenue to train new pathologists! Apart from diagnosis, the clinical text classification platform can help pathologists to provide personalised treatments depending on the mutation type and also gear towards research as an opportunity to find novel therapies for colorectal cancer patients. This website and machine learning tools can all in all improve patients prognosis and outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R.E.A.D website:\n",
    "\n",
    "#### A website is created for clinical evidence text classification into 9 mutation types. A more sophisticated platform that allows pathologists to interact and annotate uploaded images for tumour/stroma classification is on the way! A forum page is also added to discuss research articles related to colorectal cancer diagnosis and treatments in addition to a blog page. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/topcover.jpg\" width=\"1000\" height=\"50\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
