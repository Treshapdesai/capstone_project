{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/topcover.jpg\" width=\"1000\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For diagnosis purposes, the accuracy score should be much higher. Also, there is greater interest in differentiating between  stroma (connective tissue) vs tumour tissue than classifying the 8 classes of tissues in previous sections. Therefore, greater emphasis is placed on differentiating stroma vs tumour tissues.\n",
    "\n",
    "Stroma are connective tissues and the stroma to tumour ratio could affect the prognosis of the cancer. A paper mentioned that (Bianconi et al, 2015) in early cervical carcinoma, the disease-free and overall survival were found significantly better in the stroma-poor than in the stroma-rich group. Therefore, the images of interest for pathologists would come from 2 classes, stroma and tumour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification of 8 classes, Random Forests Support Vector Machine and Convulated Neural Networks had the best scores. Therefore, these two models will be adopted as models for prediction of tumour vs stroma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of colorectal cancer images into 2 classes: Tumour VS Stroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports relevant modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorectalx = pd.read_csv('../data/colorectal12.csv')\n",
    "colorectalx.drop(columns = 'label', inplace=True)\n",
    "colorectaly = pd.read_csv('../data/colorectal12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data for modelling \n",
    "\n",
    "X = colorectalx\n",
    "y = colorectaly['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.5\n",
       "1    0.5\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution since this is a classification problem\n",
    "\n",
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into the training and testing sets\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaler applied\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_val = ss.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Random Forests \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mean score: 0.9367\n"
     ]
    }
   ],
   "source": [
    "# preliminar modeling with cross val score\n",
    "\n",
    "pre_score = cross_val_score(estimator = rf,\n",
    "                            X = X_train, \n",
    "                            y = y_train,\n",
    "                            scoring = 'accuracy',\n",
    "                            cv = 10,\n",
    "                            verbose = 0)\n",
    "\n",
    "print('Random Forest mean score: %5.4f' %np.mean(pre_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9402409466780725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 200}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearch for random forests\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(rf, param_grid=rf_params, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions using Random Forests\n",
    "\n",
    "predictions = gs.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests using GridSearchCV\n",
    "\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9467312348668281"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests using GridSearchCV\n",
    "\n",
    "gs.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gs.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[194,  13],\n",
       "       [  9, 197]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 194\n",
      "False Positives: 13\n",
      "False Negatives: 9\n",
      "True Positives: 197\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(gs, X_val, y_val, cmap='viridis', \n",
    "                      values_format='d', display_labels=['1', '2']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate support vector machine.\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV(estimator=SVC(),\n",
    "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf', 'poly'), 'degree':[2]})\n",
    "gs1.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = gs1.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97610513739546"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9249394673123487"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = gs1.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[189,  18],\n",
       "       [ 13, 193]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn1, fp1, fn1, tp1 = confusion_matrix(y_val, predictions1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 189\n",
      "False Positives: 18\n",
      "False Negatives: 13\n",
      "True Positives: 193\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn1)\n",
    "print(\"False Positives: %s\" % fp1)\n",
    "print(\"False Negatives: %s\" % fn1)\n",
    "print(\"True Positives: %s\" % tp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(gs1, X_val, y_val, cmap='viridis', \n",
    "                      values_format='d', display_labels=['1', '2']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = colorectalx\n",
    "y1 = colorectaly['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.5\n",
       "1    0.5\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X1 = X1.values.reshape(-1,64,64,1)       # shaping for the Keras\n",
    "y1 = y1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = utils.to_categorical(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into the training and testing sets\n",
    "\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(X1, y1, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (1000, 64, 64, 1)\n",
      "x_val.shape:  (250, 64, 64, 1)\n",
      "y_train.shape:  (1000, 3)\n",
      "y_val.shape:  (250, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \",X1_train.shape)\n",
    "print(\"x_val.shape: \",X1_val.shape)\n",
    "print(\"y_train.shape: \",y1_train.shape)\n",
    "print(\"y_val.shape: \",y1_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 64, 64, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of an image.\n",
    "X1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of an image.\n",
    "X1_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a CNN.\n",
    "cnn_model_2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolutional layer.\n",
    "cnn_model_2.add(Conv2D(filters=128,             # number of filters\n",
    "                       kernel_size=(5,5),      # height/width of filter\n",
    "                       activation='relu',\n",
    "                       padding = 'same',# activation function \n",
    "                       input_shape=(64,64,1))) # shape of input (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a pooling layer.\n",
    "cnn_model_2.add(MaxPooling2D(pool_size=(2,2))) # dimensions of region of pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_2.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another convolutional layer.\n",
    "cnn_model_2.add(Conv2D(64,\n",
    "                       kernel_size=(3,3),\n",
    "                       activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another pooling layer.\n",
    "cnn_model_2.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_2.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another convolutional layer.\n",
    "cnn_model_2.add(Conv2D(64,\n",
    "                       kernel_size=(3,3),\n",
    "                       activation='relu'))\n",
    "\n",
    "# Add another pooling layer.\n",
    "cnn_model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cnn_model_2.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_2.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_2.add(Dense(256, activation='relu'))\n",
    "cnn_model_2.add(Dense(64, activation='relu'))\n",
    "cnn_model_2.add(Dense(32, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_2.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 128)       3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 722,755\n",
      "Trainable params: 722,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "cnn_model_2.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=0.5, \n",
    "        zoom_range = 0.5, \n",
    "        width_shift_range=0.5,  \n",
    "        height_shift_range=0.5, \n",
    "        horizontal_flip=True, \n",
    "        vertical_flip=True)\n",
    "\n",
    "datagen.fit(X1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4801 - accuracy: 0.5020 - val_loss: 0.4690 - val_accuracy: 0.5920\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.4656 - accuracy: 0.5120 - val_loss: 0.4628 - val_accuracy: 0.5640\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.4568 - accuracy: 0.4960 - val_loss: 0.4375 - val_accuracy: 0.5560\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.4457 - accuracy: 0.5640 - val_loss: 0.4213 - val_accuracy: 0.6800\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4238 - accuracy: 0.6410 - val_loss: 0.3755 - val_accuracy: 0.8640\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3669 - accuracy: 0.7890 - val_loss: 0.2890 - val_accuracy: 0.8400\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3160 - accuracy: 0.7850 - val_loss: 0.2536 - val_accuracy: 0.8800\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2335 - accuracy: 0.8700 - val_loss: 0.1764 - val_accuracy: 0.9360\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.1864 - accuracy: 0.8920 - val_loss: 0.1532 - val_accuracy: 0.9200\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.1956 - accuracy: 0.8760 - val_loss: 0.1604 - val_accuracy: 0.9440\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.1797 - accuracy: 0.9080 - val_loss: 0.1089 - val_accuracy: 0.9600\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.1523 - accuracy: 0.9180 - val_loss: 0.0923 - val_accuracy: 0.9520\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1527 - accuracy: 0.9140 - val_loss: 0.0934 - val_accuracy: 0.9720\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1389 - accuracy: 0.9210 - val_loss: 0.1185 - val_accuracy: 0.9560\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.1667 - accuracy: 0.9110 - val_loss: 0.0871 - val_accuracy: 0.9680\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 17s 4s/step - loss: 0.1388 - accuracy: 0.9330 - val_loss: 0.0956 - val_accuracy: 0.9640\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.1333 - accuracy: 0.9220 - val_loss: 0.0924 - val_accuracy: 0.9720\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1281 - accuracy: 0.9250 - val_loss: 0.0712 - val_accuracy: 0.9680\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1450 - accuracy: 0.9250 - val_loss: 0.0785 - val_accuracy: 0.9760\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 17s 4s/step - loss: 0.1254 - accuracy: 0.9300 - val_loss: 0.0914 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb908c1cf10>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_2.fit_generator(datagen.flow(X1_train,y1_train, batch_size=200),\n",
    "                              epochs = 20, validation_data = (X1_val,y1_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary table for Colorectal Cancer Classification models for 2 Tissue type classes:**\n",
    "\n",
    "| Model| Test Accuracy|Baseline score|\n",
    "|:---------:|:---:|:--------:|\n",
    "|  Random Forests |    0.947 |  0.5  |\n",
    "|SVC|  0.925 |0.5|\n",
    "|CNN| 0.960| 0.5|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN model has done well to differentiate between Stroma and Tumour tissues. Pathologist could adopt this model to make more accurate diagnosis and not only differentiate between the 2 tissue types, but decide on the severity of the cancer based on the tumour:stroma ratio. Perhaps if the stroma:tumour ratio is high, it could set as an alarm on the severity of the disease.  \n",
    "\n",
    "##### Therefore, a website can be created as a database to classify the input colorectal cancer image into Tumour or Stroma by first converting it into pixel data. The next notebook uses raw images (instead of pixel data) for classification using CNN which been the best model for classification of the 2 classes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
