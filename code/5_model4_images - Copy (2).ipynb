{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/topcover.jpg\" width=\"1000\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:teal\"> Image Classification : Stroma vs Tumour </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook classifies images of two tissue types namely, stroma and tumour for better results and accuracy as compared to classifying into 8 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data generator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, # rotation\n",
    "        width_shift_range=0.2, # horizontal shift\n",
    "        height_shift_range=0.2, # vertical shift\n",
    "        zoom_range=0.2, # zoom\n",
    "        horizontal_flip=True, # horizontal flip\n",
    "        brightness_range=[0.2,1.2]) # brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 834 images belonging to 2 classes.\n",
      "Found 425 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('../data/val1/', class_mode='binary', batch_size=5)\n",
    "# load and iterate validation dataset\n",
    "val_it = datagen.flow_from_directory('../data/train/', class_mode='binary', batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape=(5, 256, 256, 3), min=0.000, max=255.000\n"
     ]
    }
   ],
   "source": [
    "# batch shape\n",
    "\n",
    "batchX, batchy = train_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run Convulation Neural Network Model using images as data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "16/16 [==============================] - 75s 5s/step - loss: 38.2721 - accuracy: 0.5380 - val_loss: 0.6791 - val_accuracy: 0.5600\n",
      "Epoch 2/12\n",
      "16/16 [==============================] - 117s 7s/step - loss: 0.6872 - accuracy: 0.5379 - val_loss: 0.6775 - val_accuracy: 0.6400\n",
      "Epoch 3/12\n",
      "16/16 [==============================] - 102s 6s/step - loss: 0.6531 - accuracy: 0.5987 - val_loss: 0.8811 - val_accuracy: 0.5360\n",
      "Epoch 4/12\n",
      "16/16 [==============================] - 101s 6s/step - loss: 0.7846 - accuracy: 0.5492 - val_loss: 0.6797 - val_accuracy: 0.6160\n",
      "Epoch 5/12\n",
      "16/16 [==============================] - 100s 6s/step - loss: 0.6974 - accuracy: 0.5865 - val_loss: 0.6983 - val_accuracy: 0.4320\n",
      "Epoch 6/12\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.6954 - accuracy: 0.4770 - val_loss: 0.6963 - val_accuracy: 0.4560\n",
      "Epoch 7/12\n",
      "16/16 [==============================] - 88s 6s/step - loss: 0.6909 - accuracy: 0.5456 - val_loss: 0.6935 - val_accuracy: 0.5040\n",
      "Epoch 8/12\n",
      "16/16 [==============================] - 82s 5s/step - loss: 0.6992 - accuracy: 0.4196 - val_loss: 0.6988 - val_accuracy: 0.4080\n",
      "Epoch 9/12\n",
      "16/16 [==============================] - 109s 7s/step - loss: 0.6862 - accuracy: 0.6302 - val_loss: 0.6967 - val_accuracy: 0.4480\n",
      "Epoch 10/12\n",
      "16/16 [==============================] - 101s 6s/step - loss: 0.6948 - accuracy: 0.4848 - val_loss: 0.6919 - val_accuracy: 0.5280\n",
      "Epoch 11/12\n",
      "16/16 [==============================] - 105s 7s/step - loss: 0.7000 - accuracy: 0.3970 - val_loss: 0.6933 - val_accuracy: 0.5040\n",
      "Epoch 12/12\n",
      "16/16 [==============================] - 101s 6s/step - loss: 0.6944 - accuracy: 0.4830 - val_loss: 0.6958 - val_accuracy: 0.4400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x9d30236280>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128,             # number of filters\n",
    "                       kernel_size=(5,5),      # height/width of filter\n",
    "                       activation='relu',\n",
    "                       padding = 'same',# activation function \n",
    "                       input_shape=(256, 256, 3))) # shape of input (image)\n",
    "\n",
    "# Add a pooling layer.\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "# Add another convolutional layer.\n",
    "model.add(Conv2D(64,\n",
    "                       kernel_size=(3,3),\n",
    "                       activation='relu'))\n",
    "\n",
    "# Add another pooling layer.\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# Add another convolutional layer.\n",
    "model.add(Conv2D(64,\n",
    "                       kernel_size=(3,3),\n",
    "                       activation='relu'))\n",
    "\n",
    "# Add another pooling layer.\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit model\n",
    "model.fit(train_it,epochs = 12, steps_per_epoch=16, validation_data=val_it, validation_steps=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_cifar10_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN validation accuracy results are 0.7120. This model can be used to classify histopathological images based on stroma vs tumour on the website that has been created. It can be expanded to benign vs cancer for gastrointestinal tissues if more data is available for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
